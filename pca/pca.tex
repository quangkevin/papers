\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{pgf,tikz}

\title{Principal Component Analysis (PCA) \\ Machine Learning Group}
\date{2018-02-21}
\author{Kevin Nguyen, MatchCraft LLC}

\begin{document}
\maketitle

\begin{algorithm}
  \caption{Calculate PCA}
  \begin{algorithmic}
    \State $X \gets [x_1, x_2, \dots, x_n]_{d \times n}$ \Comment{Dataset}
    \State $\mu \gets Mean(X)$ \Comment{Find the mean of each dimension}
    \State $X \gets X - \mu$ \Comment{Shift each point to center around the mean}
    \State $S \gets Cov(X,X)$ \Comment{Find the covariance matrix of X}
    \State $[U,\lambda] \gets eig(S)$ \Comment{principal component vectors and variance}
  \end{algorithmic}
\end{algorithm}


\section{Matrix}
\subsection{Definition}
Let X be d x n matrix where d is number of rows and n is number of columns.

$$
X =
\begin{bmatrix}
  x_{11} & x_{12} & x_{13} & \dots & x_{1n} \\
  x_{21} & x_{22} & x_{13} & \dots & x_{2n} \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  x_{d1} & x_{d2} & x_{d3} & \dots & x_{dn} \\
\end{bmatrix}
=
\begin{pmatrix}
  x_{11} & x_{12} & x_{13} & \dots & x_{1n} \\
  x_{21} & x_{22} & x_{13} & \dots & x_{2n} \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  x_{d1} & x_{d2} & x_{d3} & \dots & x_{dn} \\
\end{pmatrix}
= (x_{ij}) \in \mathbb{R}^{d \times n}
$$

\subsection{Transpose}

$$
X^T = 
\begin{bmatrix}
  x_{11} & x_{21} & x_{31} & \dots & x_{d1} \\
  x_{12} & x_{22} & x_{32} & \dots & x_{d2} \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  x_{1n} & x_{2n} & x_{3n} & \dots & x_{dn} \\
\end{bmatrix}
=
\begin{pmatrix}
  x_{11} & x_{21} & x_{31} & \dots & x_{d1} \\
  x_{12} & x_{22} & x_{32} & \dots & x_{d2} \\
  \vdots & \vdots & \vdots & \ddots & \vdots \\
  x_{1n} & x_{2n} & x_{3n} & \dots & x_{dn} \\
\end{pmatrix}
= (x_{ji}) \in \mathbb{R}^{n \times d}
$$

\newpage

\subsection{Matrix Multiplication}
If X is d x n matrix and Y is n x m matrix, then XY is d x m matrix. $XY_{ij}$ is the value of row i column j of matrix XY.

$$XY_{ij} = x_{i1}y_{1j} + x_{i2}y_{2j} + x_{i3}y_{3j} + \dots x_{in}y_{nj} = \sum_{k=1}^{n}x_{ik}y_{kj}$$

$$
S = 
\frac{1}{n}XX^T
=\frac{1}{n}
\begin{bmatrix}
  x_{11} & x_{12} & \dots & x_{1n} \\
  x_{21} & x_{22} & \dots & x_{2n} \\
  \vdots & \vdots & \ddots & \vdots \\
  x_{d1} & x_{d2} & \dots & x_{dn} \\
\end{bmatrix}
\begin{bmatrix}
  x_{11} & x_{21} & \dots & x_{d1} \\
  x_{12} & x_{22} & \dots & x_{d2} \\
  \vdots & \vdots & \ddots & \vdots \\
  x_{1n} & x_{2n} & \dots & x_{dn} \\
\end{bmatrix}
\\
=
\begin{bmatrix}
  X_{1}X_{1}^T & X_{1}X_{2}^T & \dots & X_{1}X_{d}^T \\
  X_{2}X_{1}^T & X_{2}X_{2}^T & \dots & X_{2}X_{d}^T \\  
  \vdots & \vdots  & \ddots & \vdots \\
  X_{d}X_{1}^T & X_{d}X_{2}^T & \dots & X_{d}X_{d}^T \\  
\end{bmatrix}
$$

\section{Vectors}
Let \textbf{x} and \textbf{u} vector vector of d dimension. The projection of \textbf{x} onto \textbf{u} is

\begin{center}
  \begin{tikzpicture}[scale=.5]
    \coordinate (origin) at (0,0);
  \draw[->] (0,0) -- (2,5) node (u) [pos=.9,sloped, above]{$\mathbf{x}$};
  \draw[line width=1pt] (0, 0) -- (3.639344262295082, 3.0327868852459017) node (proj_u) [pos=.5,sloped, below]{$\frac{\mathbf{x} \cdot \mathbf{u}}{\left \| \mathbf{u} \right \|}$};
  \draw[->] (3.639344262295082, 3.0327868852459017) -- (6,5) node (u) [pos=.9,sloped, below]{$\mathbf{u}$};
  \draw[dashed, ->] (2,5) -- (3.639344262295082, 3.0327868852459017);
  \draw (0.7682212795973759, 0.6401843996644798) arc (39.8055710922652:68.1985905:1) node at (.78,1.2) {$\theta$};

  \node [right=1cm,text width=8cm] at (5,3) {
    $$
    \begin{aligned}
      \mathbf{x} \cdot \mathbf{u} &= \left \| \mathbf{x} \right \| \left \| \mathbf{u} \right \| \cos \theta \\
      &= x_1 u_1 + x_2 u_2 + \dots + x_d u_d \\
      &= u_1 x_1 + u_2 x_2 + \dots + u_d x_d \\      
      &=
      \begin{pmatrix}
        u_1 & u_2 &  \dots & u_d \\
      \end{pmatrix}
      \begin{pmatrix}
        x_1 \\ x_2 \\ \vdots \\ x_d \\
      \end{pmatrix} \\
      &= U^{T}X
    \end{aligned}
    $$
  };
\end{tikzpicture}
\end{center}

\section{Lagrange Multipliers}

\section{Statistics}
\subsection{Variance}

Let X be a dataset of size n.

$$X = [x_1, x_2, ..., x_n]$$

Mean of X

$$E[X] = \mu = \frac{1}{n}\sum_{i=1}^{n}x_i$$

Variance of X is the average of square distance from the mean.

$$Var(X) = \sigma^2 = \frac{1}{n}\sum_{i=1}^{n} (x_i - \mu)^2$$

Shift X to center around its mean

$$Var(X)
= \sigma^2
= \frac{1}{n}\sum_{i=1}^{n}(x_i)^2
= \frac{1}{n}
\begin{pmatrix}
  x_1 & x_2 &  \dots & x_n \\
\end{pmatrix}
\begin{pmatrix}
  x_1 \\ x_2 \\ \vdots \\ x_n \\
\end{pmatrix}
= \frac{1}{n}XX^T
$$

\begin{algorithm}
  \caption{Derivation of PCA}
  \begin{algorithmic}
    \State $X \gets
    \begin{bmatrix}
      x_{11} & x_{12} & x_{13} & \dots & x_{1n} \\
      x_{21} & x_{22} & x_{13} & \dots & x_{2n} \\
      \vdots & \vdots & \vdots & \ddots & \vdots \\
      x_{d1} & x_{d2} & x_{d3} & \dots & x_{dn} \\
    \end{bmatrix}$
    , $U
    \gets \begin{bmatrix}
      u_1 \\
      u_2 \\
      \vdots \\
      u_d \\
    \end{bmatrix}$ 
    \State \\
    \State $f \gets Var(U^T X)$ \Comment{Maximize variance}
    \State \\
    \State $g \gets U^{T}U - 1 = 0$ \Comment{Constraint}
    
    $$\operatorname{argmax}_{u_1, u_2, \dots, u_d} f \text{ subject to } g$$

    $$
    \begin{aligned}
      f &= Var(U^T X) \\
      &= \frac{1}{n}(U^T X)(U^T X)^T \text{ because } Var(X) = \frac{1}{n} XX^T \\
      &= \frac{1}{n}(U^T X)(X^T U) \text{ because } (AB)^T = B^T A^T \\
      &= \frac{1}{n}U^T X X^T U \\
      &= U^{T}SU \text{ where } S = Cov(X,X) = \frac{1}{n}X X^T \\
      \nabla_\mathbf{u} f &= \lambda \nabla_\mathbf{u} g \text{ for some } \lambda \\
      \nabla_\mathbf{u} U^{T}SU &= \lambda \nabla_\mathbf{u} (U^{T}U - 1) \\
      2SU &= 2\lambda U \\
      SU &= \lambda U \implies \text{ Definition of Eigenvalues and Eigenvectors}\\
      \\
      f &= Var(U^T X) \\
      &= U^{T}SU \\
      &= U^{T} (\lambda U) \\
      &= \lambda U^T U \\ 
      &= \lambda
    \end{aligned}
    $$
  \end{algorithmic}
  \end{algorithm}
\end{document}
